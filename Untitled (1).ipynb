{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle-OpenStreetMap-Data\n",
    "\n",
    "On the particular project, I am using data mungling techniques to assess the quality of OpenStreetMapâ€™s (OSM) data for the mumbai city regarding their consistency and uniformity. The data wrangling takes place programmatically, using Python for the most of the process and SQL for items that need further attention.\n",
    "\n",
    "The dataset describes the city of mumbai.Mumbai,India is the closest thing I have to a hometown in the India as I lived there for a good chunk of my childhood, so I was keen to take a look at it in this new, OpenStreetMap-based lens. The size of the dataset is 66 MB and can can be downloaded from here: https://mapzen.com/data/metro-extracts/metro/mumbai_india/\n",
    "\n",
    "About the project\n",
    "\n",
    "Scope\n",
    "\n",
    "OpenStreetMap (OSM) is a collaborative project to create a free editable map of the world. The creation and growth of OSM have been motivated by restrictions on use or availability of map information across much of the world, and the advent of inexpensive portable satellite navigation devices.\n",
    "\n",
    "On the specific project, I am using data from https://www.openstreetmap.org/node/16173235 and data mungling techniques, to assess the quality of their validity, accuracy, completeness, consistency and uniformity. The biggest part of the wrangling takes place programmatically using Python and then the dataset is entered into a SQL database for further examination of any remaining elements that need attention. Finally, I perform some basic exploration and express some ideas for additional improvements.\n",
    "\n",
    "Skills demonstrated\n",
    "\n",
    "Assessment of the quality of data for validity, accuracy, completeness, consistency and uniformity. Parsing and gathering data from popular file formats such as .xml and .csv. Processing data from very large files that cannot be cleaned with spreadsheet programs. Storing, querying, and aggregating data using SQL. Mumbai, India\n",
    "\n",
    "https://www.openstreetmap.org/node/16173235 https://mapzen.com/data/metro-extracts/metro/mumbai_india/\n",
    "\n",
    "Problems Encountered in the Map\n",
    "\n",
    "Problems Encountered in the Map Once the location was decided, I downloaded the full extract of the region and ran Python code to investigate any issues with the data. The following problems were discovered:\n",
    "\n",
    "Street Names: Incomplete ('hanuman raod ___') or incorrect names ('Zhopadpatti'), along with street abbreviations ('rd.' instead of 'Road')\n",
    "\n",
    "Postal Codes: Inconsistent postal code formats ('500023' and '120045') and incorrect post codes ('123')\n",
    "\n",
    "To tackle these issues, I had to create python scripts to clean each respective category of data. Auditing part is explained in Openstreetmap.ipynb notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created mumbai_sample file which is part of mumbai_india file and it can be used for various experiments before using those on main osm file, we can also get the idea about the format of osm file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different types of tags mumbai_india file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, I matched them against a list of acceptable street types. If they weren't in the list of expected types, they would be added to a dictionary as keys, with the addresses that contain the problematic cases as the values.\n",
    "\n",
    "Having this overview allowed me to determine what my auditing function needed to accomplish. I created a dictionaries for mapping/correcting purposes - 'mapping'. If my function came across a problematic street type, it would refer to that dictionaries for the corrected version to be replaced with.\n",
    "\n",
    "An analysis of the XML data, along with outside research on Google Maps and OpenStreetMaps, was needed to identify the missing street types for the incomplete street names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview\n",
    "In this section, I'll execute a number of SQL queries in order to analyze the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users with most numbers of contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'parambyte', 69327),\n",
      " (u'PlaneMad', 68363),\n",
      " (u'anushap', 62553),\n",
      " (u'Ashok09', 62208),\n",
      " (u'Narsimulu', 55611),\n",
      " (u'Srikanth07', 53795),\n",
      " (u'premkumar', 51097)]\n"
     ]
    }
   ],
   "source": [
    "sql_file=\"mumbai_india.db\"\n",
    "con = sqlite3.connect(sql_file)\n",
    "cur = con.cursor()\n",
    "cur.execute('SELECT user,count(*) FROM nodes GROUP BY user ORDER BY count(*) DESC LIMIT 7')\n",
    "all_rows=cur.fetchall()\n",
    "pprint(all_rows)\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'building', 223631),\n",
      " (u'highway', 40437),\n",
      " (u'name', 11741),\n",
      " (u'oneway', 4466),\n",
      " (u'source', 4142),\n",
      " (u'landuse', 3038),\n",
      " (u'levels', 2673)]\n"
     ]
    }
   ],
   "source": [
    "sql_file=\"mumbai_india.db\"\n",
    "con = sqlite3.connect(sql_file)\n",
    "cur = con.cursor()\n",
    "cur.execute('SELECT key,count(*) FROM ways_tags GROUP BY key ORDER BY count(*) DESC LIMIT 7')\n",
    "all_rows=cur.fetchall()\n",
    "pprint(all_rows)\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of unique users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1739,)]\n"
     ]
    }
   ],
   "source": [
    "sql_file=\"mumbai_india.db\"\n",
    "con = sqlite3.connect(sql_file)\n",
    "cur = con.cursor()\n",
    "cur.execute('SELECT COUNT(DISTINCT(e.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e')\n",
    "all_rows=cur.fetchall()\n",
    "pprint(all_rows)\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of users who contributed for less than 8 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1053,)]\n"
     ]
    }
   ],
   "source": [
    "sql_file=\"mumbai_india.db\"\n",
    "con = sqlite3.connect(sql_file)\n",
    "cur = con.cursor()\n",
    "cur.execute('SELECT COUNT(*) FROM (SELECT e.user, COUNT(*) as num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) as e GROUP BY e.user HAVING num<=8)  u')\n",
    "all_rows=cur.fetchall()\n",
    "pprint(all_rows)\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different types of cuisines available in mumbai and number of restaurants it is available in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'indian', 66),\n",
      " (u'regional', 21),\n",
      " (u'pizza', 14),\n",
      " (u'vegetarian', 13),\n",
      " (u'chinese', 12),\n",
      " (u'italian', 11),\n",
      " (u'burger', 5),\n",
      " (u'international', 5),\n",
      " (u'seafood', 4),\n",
      " (u'asian', 3),\n",
      " (u'South_Indian', 2),\n",
      " (u'all_types_of_food', 2),\n",
      " (u'lebanese', 2),\n",
      " (u'Indian,_Chinese_etc', 1),\n",
      " (u'Seafood', 1),\n",
      " (u'Vegetarian_Restaurant', 1),\n",
      " (u'american', 1),\n",
      " (u'cafe', 1),\n",
      " (u'chicken;fish;indian', 1),\n",
      " (u'chicken;kebab;indian', 1),\n",
      " (u'chicken_,fish,cafe', 1),\n",
      " (u'fast_food', 1),\n",
      " (u'grill;coffee_shop;asian;noodles;fish_and_chips;diner;chicken;italian_pizza;indian;curry;fish;french;friture;chinese;barbecue',\n",
      "  1),\n",
      " (u'indian;south_indian', 1),\n",
      " (u'indian_aagri', 1),\n",
      " (u'italian_pizza;pizza', 1),\n",
      " (u'lebanese,_chinese,_indian', 1),\n",
      " (u'local', 1),\n",
      " (u'mediterranean', 1),\n",
      " (u'only_vegiterian', 1),\n",
      " (u'oriental', 1),\n",
      " (u'persian', 1),\n",
      " (u'sad_food', 1),\n",
      " (u'south Indian; Punjabi; agari; malwani; Chinese', 1),\n",
      " (u'south_indian', 1),\n",
      " (u'south_indian,_chinese', 1),\n",
      " (u'spanish', 1),\n",
      " (u'sweets_shop', 1),\n",
      " (u'thai', 1),\n",
      " (u'vegan;ice_cream;italian_pizza;indian;vegetarian;local', 1),\n",
      " (u'vegetarian;indian', 1)]\n"
     ]
    }
   ],
   "source": [
    "sql_file=\"mumbai_india.db\"\n",
    "con = sqlite3.connect(sql_file)\n",
    "cur = con.cursor()\n",
    "cur.execute('SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value=\"restaurant\") as i ON nodes_tags.id=i.id WHERE nodes_tags.key=\"cuisine\" GROUP BY nodes_tags.value ORDER BY num DESC')\n",
    "all_rows=cur.fetchall()\n",
    "pprint(all_rows)\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different religions and number of places where they are workshipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'hindu', 125),\n",
      " (u'muslim', 71),\n",
      " (u'christian', 34),\n",
      " (u'buddhist', 13),\n",
      " (u'jain', 6),\n",
      " (u'sikh', 4),\n",
      " (u'zoroastrian', 2),\n",
      " (u'jewish', 1)]\n"
     ]
    }
   ],
   "source": [
    "sql_file=\"mumbai_india.db\"\n",
    "con = sqlite3.connect(sql_file)\n",
    "cur = con.cursor()\n",
    "cur.execute('SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags  JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value=\"place_of_worship\") as i ON nodes_tags.id=i.id WHERE nodes_tags.key=\"religion\" GROUP BY nodes_tags.value ORDER BY num DESC')\n",
    "all_rows=cur.fetchall()\n",
    "pprint(all_rows)\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different leisures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'park', 63),\n",
      " (u'playground', 20),\n",
      " (u'sports_centre', 15),\n",
      " (u'garden', 10),\n",
      " (u'fitness_centre', 8),\n",
      " (u'pitch', 6),\n",
      " (u'swimming_pool', 4),\n",
      " (u'aquarium', 1),\n",
      " (u'fitness_station', 1),\n",
      " (u'golf_course', 1),\n",
      " (u'stadium', 1)]\n"
     ]
    }
   ],
   "source": [
    "sql_file=\"mumbai_india.db\"\n",
    "con = sqlite3.connect(sql_file)\n",
    "cur = con.cursor()\n",
    "cur.execute('SELECT nodes_tags.value, count(*) as num FROM nodes_tags  WHERE nodes_tags.key=\"leisure\" GROUP BY nodes_tags.value ORDER BY num DESC')\n",
    "all_rows=cur.fetchall()\n",
    "pprint(all_rows)\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names of few corrected streets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Hanuman Road', 78),\n",
      " (u'Yashavant Nagar Road', 29),\n",
      " (u'Hiranandani Estate', 24),\n",
      " (u'P.L. Lokhande Marg', 24),\n",
      " (u'New Link Road, Andheri West', 21),\n",
      " (u'LBS Marg', 18),\n",
      " (u'Road Number 3', 18),\n",
      " (u'Thane Ghodbunder Road', 18),\n",
      " (u'Eastern Express Highway', 14),\n",
      " (u'GD Somani Road', 13)]\n"
     ]
    }
   ],
   "source": [
    "sql_file=\"mumbai_india.db\"\n",
    "con = sqlite3.connect(sql_file)\n",
    "cur = con.cursor()\n",
    "cur.execute('SELECT value, count(*) as num FROM nodes_tags WHERE key=\"street\" GROUP BY value ORDER BY num DESC LIMIT 10')\n",
    "\n",
    "all_rows=cur.fetchall()\n",
    "pprint(all_rows)\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cities surrounding mumbai and number of nodes in those cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Mumbai', 607),\n",
      " (u'Bandra, Mumbai', 566),\n",
      " (u'mumbai', 187),\n",
      " (u'Virar West', 91),\n",
      " (u'Mulund (West)', 79),\n",
      " (u'Navi Mumbai', 70),\n",
      " (u'MUMBAI', 68),\n",
      " (u'Mulund (East)', 62),\n",
      " (u'Thane', 49),\n",
      " (u'Kharghar', 43)]\n"
     ]
    }
   ],
   "source": [
    "sql_file=\"mumbai_india.db\"\n",
    "con = sqlite3.connect(sql_file)\n",
    "cur = con.cursor()\n",
    "cur.execute('SELECT tags.value, COUNT(*) as count FROM (SELECT * FROM nodes_tags UNION ALL  SELECT * FROM ways_tags) tags WHERE tags.key LIKE \"%city\" GROUP BY tags.value ORDER BY count DESC LIMIT 10')\n",
    "\n",
    "all_rows=cur.fetchall()\n",
    "pprint(all_rows)\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different postcodes in ways_tags after using update postcode function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'car_rental', 1),\n",
      " (u'cold_storage', 1),\n",
      " (u'conference_centre', 1),\n",
      " (u'cyber_cafe', 1),\n",
      " (u'electric socket', 1),\n",
      " (u'internet_cafe', 1),\n",
      " (u'meditation_centre', 1),\n",
      " (u'parking_entrance', 1),\n",
      " (u'parking_space', 1),\n",
      " (u'picnic spot', 1)]\n"
     ]
    }
   ],
   "source": [
    "sql_file=\"mumbai_india.db\"\n",
    "con = sqlite3.connect(sql_file)\n",
    "cur = con.cursor()\n",
    "cur.execute('SELECT value, COUNT(*) as count FROM nodes_tags WHERE key=\"amenity\" GROUP BY value ORDER BY count LIMIT 10')\n",
    "\n",
    "all_rows=cur.fetchall()\n",
    "pprint(all_rows)\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Additional Improvements\n",
    "\n",
    "There are several areas of improvement of the project in the future. The first one is on the completeness of the data. All the above analysis is based on a dataset that reflects a big part of mumbai but not only mumbai. The reason for this is the lack of a way to download a dataset for the entire mumbai without including parts of the neighboring cities. The analyst has to either select a part of the island/city or select a wider area that includes parts of thane and ratnagiri. Also, because of relations between nodes, ways, and relations, the downloaded data expand much further than the actual selection.\n",
    "\n",
    "As a future improvement, I would download a wider selection or the metro extract from MapZen and filter the non-mumbai nodes and their references. The initial filtering could take place by introducing some latitude/longitude limits in the code to sort out most of the \"non-m\" nodes.\n",
    "\n",
    "The second area with room for future improvement is the exploratory analysis of the dataset. Just to mention some of the explorings that could take place:\n",
    "\n",
    "\n",
    "1.Popular franchises in the country (fast food, conventional stores, etc.)\n",
    "\n",
    "2.Selection of a bank based on the average distance you have to walk for an ATM.\n",
    "\n",
    "3.Which area has the biggest parks and recreation spaces.\n",
    "\n",
    "The scope of the current project was the wrangling of the dataset, so all the above have been left for future improvement.\n",
    "\n",
    "Increasing Submissions\n",
    "\n",
    "Going through this dataset, my concerns were less with the cleanliness of the data - as I found it surprisingly clean - and more with the lack of data. This part of mumbai is too big to have as little information as it does. I think OpenStreetMap can go a long way in developing their map database if they took on certain initiative to increase engagement with their service. One possible initiative would be for OpenStreetMap to form partnerships with educational institutions such as schools, or maybe libraries, to engage students with their service. As a way to develop computer and internet literacy, computer-related courses can teach students how to use OpenStreetMap. It'll expose them to online maps, GPS technology, how to participate in open source projects, and more - all while adding data to a free resource that could benefit the members of the community and the world.\n",
    "\n",
    "Anticipated Problem: However, the concern here is that you might see an influx of dirty, unreliable data, particularly if the people behind them aren't very computer literate or only participating because it's a mandatory portion of a course. Naturally the data that come from volunteers who get involved because of their genuine passion for the project would be of higher quality.\n",
    "\n",
    "Ensuring Data Consistency\n",
    "\n",
    "For data improvement, the biggest problem I came across my data before I cleaned it was the lack of a unified format for street types or phone numbers, or simply incomplete information. If OpenStreetMap had a hard format that street types, phone numbers, zip codes, etc. should follow - and they ensured the format is appropriate for the city/country - there would be much cleaner data for analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "It's clear from what we've seen that the mumbai OpenStretMap data is still incomplete and incorrect but there is still much in this city to be found and explored. The upside is that a lot of the data that has been entered is fairly clean, so future OSM users who embark on the task of improving the dataset with new data won't have much to worry about with regards to cleaning prior submissions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
